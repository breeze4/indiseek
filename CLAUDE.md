# Indiseek

Codebase research service. Python 3.10+.

## Instructions:
docs/diagrams/ is generated by scripts/generate_diagrams.py - this is excalidraw. Currently the .excalidraw files are "read-only", dont actually modify them

## Setup
```
pip install -e ".[dev]"
cp .env.example .env  # then fill in values
```

## Build/Install
```
pip install -e .
```

## Test
```
pytest
```

## Lint
```
ruff check src/
```

## Generate SCIP Index (requires Node.js)
```
bash scripts/generate_scip.sh /path/to/repo
```

## Index (after repo is cloned and .env configured)
```
# Legacy single-repo (uses REPO_PATH from .env, repo_id=1)
python scripts/index.py
python scripts/index.py --scip-path /path/to/repo/index.scip --embed --summarize --lexical

# Multi-repo: index a specific repo by name or ID
python scripts/index.py --repo vite --embed --summarize --lexical
python scripts/index.py --repo 2 --embed --summarize --lexical

# Dry run: show what each stage would do without executing
python scripts/index.py --repo vite --embed --summarize --lexical --dry-run

# Filter to a subdirectory
python scripts/index.py --repo vite --filter packages/vite/src --embed
```

## Indexing Pipeline Details

The `scripts/index.py` script runs up to 5 steps. Each step is optional except Tree-sitter parsing. The flags `--embed`, `--summarize`, and `--lexical` control which optional steps run.

### Step 1: Tree-sitter Parsing (always runs)

Parses all `.ts`/`.tsx` files using Tree-sitter to extract symbols (functions, classes, interfaces, types, enums, exported variables) and AST-scoped code chunks (one chunk per top-level symbol, with a fallback module-level chunk for files with no extractable symbols). Results are stored in SQLite.

**Cost:** None. Runs locally using `tree-sitter` and `tree-sitter-typescript` Python bindings. Fast — parses thousands of files in seconds.

### Step 2: SCIP Cross-References (runs if `index.scip` exists)

Loads a pre-generated SCIP protobuf index (produced by `scip-typescript`) into SQLite. This provides precise "go to definition", "find all references", and caller/callee relationships across the entire codebase — the same data that powers GitHub Code Search and Sourcegraph.

**Cost:** None. The SCIP index must be generated beforehand via `bash scripts/generate_scip.sh /path/to/repo` (requires Node.js). Both generation and loading are local-only operations.

### Step 3: Semantic Embedding (`--embed`)

Reads all AST-scoped chunks from SQLite, embeds them in batches of 20 using the Gemini Embedding API (`gemini-embedding-001`, 768 dimensions), and stores the vectors in LanceDB. Supports resume — already-embedded chunks are skipped on re-runs.

**Cost:** Gemini Embedding API at **$0.15 per 1M input tokens** (or free on the free tier with rate limits). For Vite (~1,817 chunks, ~377k input tokens), expect roughly **~$0.06** on the paid tier.

### Step 4: File Summarization (`--summarize`)

Sends each source file (ts, tsx, js, jsx, json, md, yaml) to `gemini-2.0-flash` with a system prompt asking for a one-sentence summary of the file's responsibility. Summaries are stored in SQLite and used by the `read_map` tool to build a navigable directory tree. Files are truncated to 30k chars before sending. Supports resume — already-summarized files are skipped on re-runs. A 0.5s delay between requests avoids rate limiting.

**Cost:** Gemini 2.0 Flash API at **$0.10 per 1M input tokens / $0.40 per 1M output tokens** (or free on the free tier). This is the most API-intensive step because every source file gets its own LLM call. For Vite (~1,857 source files, ~1.2M input tokens total, ~46k output tokens), expect roughly **~$0.14** on the paid tier. This step takes the longest wall-clock time due to the per-file rate-limiting delay (~15 min at 0.5s/file).

### Step 5: Lexical Index (`--lexical`)

Builds a Tantivy BM25 full-text search index over all AST-scoped chunks from SQLite. This enables exact-match keyword search (variable names, error codes, identifiers) that semantic search misses.

**Cost:** None. Runs locally using `tantivy` (Rust-based search engine with Python bindings). Rebuilds from scratch each time, fast.

## Dashboard
```bash
# Dev mode (frontend hot-reload + API proxy)
cd frontend && npm run dev    # serves at http://localhost:5173/dashboard/
uvicorn indiseek.api.server:app  # API at http://localhost:8000

# Production mode (built SPA served by FastAPI)
cd frontend && npm run build
uvicorn indiseek.api.server:app  # dashboard at http://localhost:8000/dashboard
```

## Multi-Repo Management

Repos can be managed via the dashboard UI at `/repos` or via the API:

```bash
# List repos
curl http://localhost:8000/api/repos

# Add a repo (clones in background)
curl -X POST http://localhost:8000/api/repos \
    -H "Content-Type: application/json" \
    -d '{"name": "myrepo", "url": "https://github.com/org/myrepo.git"}'

# Check freshness (compares indexed SHA to remote HEAD)
curl -X POST http://localhost:8000/api/repos/2/check

# Sync repo (git pull + incremental re-index of changed files)
curl -X POST http://localhost:8000/api/repos/2/sync
```

All API endpoints accept `?repo_id=N` (GET) or `"repo_id": N` in body (POST), defaulting to 1.

`REPO_PATH` in `.env` is only needed for legacy single-repo usage (repo_id=1). When using the dashboard to manage repos, clones go to `DATA_DIR/repos/<id>/`.

## Serve
```
uvicorn indiseek.api.server:app
```

## Query
```bash
# Health check
curl http://localhost:8000/api/health

# Ask a question (requires GEMINI_API_KEY and completed indexing)
curl -X POST http://localhost:8000/api/query \
    -H "Content-Type: application/json" \
    -d '{"prompt": "How does Vite HMR propagation work when a CSS file changes?"}'

# Query a specific repo
curl -X POST http://localhost:8000/api/query \
    -H "Content-Type: application/json" \
    -d '{"prompt": "How does auth work?", "repo_id": 2}'
```

## Agent Tools (after indexing)
```python
from indiseek import config
from indiseek.storage.sqlite_store import SqliteStore
from indiseek.indexer.lexical import LexicalIndexer
from indiseek.tools.read_map import read_map
from indiseek.tools.resolve_symbol import resolve_symbol
from indiseek.tools.read_file import read_file
from indiseek.tools.search_code import CodeSearcher, format_results

store = SqliteStore(config.SQLITE_PATH)

# read_map — directory tree with file summaries
read_map(store)                                       # full tree
read_map(store, path="packages/vite/src/node/server") # scoped

# resolve_symbol — definitions, references, callers, callees
resolve_symbol(store, "createServer", "definition")
resolve_symbol(store, "createServer", "references")
resolve_symbol(store, "createServer", "callers")
resolve_symbol(store, "createServer", "callees")

# read_file — source code with line numbers
read_file(config.REPO_PATH, "packages/vite/src/node/server/index.ts", 1, 50)

# search_code — hybrid semantic+lexical search
lexical = LexicalIndexer(store, config.TANTIVY_PATH)
lexical.open_index()
searcher = CodeSearcher(lexical_indexer=lexical)
results = searcher.search("HMR CSS propagation", mode="hybrid", limit=10)
format_results(results, "HMR CSS propagation")
```

## Project Layout
- src/indiseek/ — main package
- src/indiseek/agent/ — agent loop (Gemini tool-calling) and LLM provider
- src/indiseek/tools/ — agent tools (read_map, search_code, resolve_symbol, read_file)
- src/indiseek/api/ — FastAPI server (all routes under /api/*, dashboard SPA at /dashboard)
- src/indiseek/indexer/pipeline.py — extracted pipeline step functions with progress callbacks
- src/indiseek/storage/sqlite_store.py — SQLite storage layer (all data tables, repo CRUD)
- src/indiseek/git_utils.py — git operations (clone, fetch, pull, SHA comparison)
- src/indiseek/config.py — environment config + per-repo path helpers
- frontend/ — React SPA dashboard (Vite + Tailwind + TanStack Query)
- scripts/ — CLI entry points (index.py with --repo support)
- tests/ — pytest tests
- docs/ — spec and plans
- proto/ — SCIP protobuf schema
